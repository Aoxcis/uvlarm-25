#!/usr/bin/python3
import rclpy
from rclpy.node import Node
import pyrealsense2 as rs
import numpy as np
import cv2
from sensor_msgs.msg import Image
from std_msgs.msg import String
from cv_bridge import CvBridge
import torch
import os


class YoloRealsense(Node):
    def __init__(self, fps=30):
        super().__init__('yolo_realsense_node')

        # YOLO Model setup
        self.model = torch.hub.load('ultralytics/yolov5', 'custom', path='o2p5/grp_pibot25/playground/weights/best.pt')
        # self.model = torch.hub.load('ultralytics/yolov5', 'custom', path='/home/e2h1/Documents/ros_space/o2p5/grp_pibot25/playground/weights/best.pt')

        self.model.conf = 0.7  # Confidence threshold
        self.model.iou = 0.8  # IoU threshold
        self.model.multi_scale = True  # Enable multi-scale detection
        # RealSense pipeline setup
        self.pipeline = rs.pipeline()
        self.config = rs.config()
        self.bridge = CvBridge()

        # Configure RealSense streams
        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, fps)
        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, fps)

        # Align depth to color
        self.align_to = rs.stream.color
        self.align = rs.align(self.align_to)

        try:
            self.pipeline.start(self.config)
            self.get_logger().info("RealSense pipeline started successfully.")
        except Exception as e:
            self.get_logger().error(f"Error starting the pipeline: {e}")
            exit(1)

        # ROS publishers
        self.color_publisher = self.create_publisher(Image, 'camera/color', 10)
        self.depth_publisher = self.create_publisher(Image, 'camera/depth', 10)
        self.detection_publisher = self.create_publisher(String, 'detection', 10)

    def read_frames(self):
        frames = self.pipeline.wait_for_frames()
        aligned_frames = self.align.process(frames)
        color_frame = aligned_frames.get_color_frame()
        depth_frame = aligned_frames.get_depth_frame()

        if not color_frame or not depth_frame:
            self.get_logger().warn("Unable to retrieve frames.")
            return None, None, None

        color_image = np.asanyarray(color_frame.get_data())
        depth_image = np.asanyarray(depth_frame.get_data())

        return color_image, depth_image, depth_frame

    def process_and_publish(self):
        color_image, depth_image, depth_frame = self.read_frames()
        if color_image is None:
            return

        # Perform YOLO inference
        results = self.model(color_image)
        detections = results.xyxy[0].tolist()  # Get detection results as a list
        detections = [d for d in detections if (d[2] - d[0]) * (d[3] - d[1]) <= 60000]
        for *box, conf, cls in detections:
            x1, y1, x2, y2 = map(int, box)
            label = f"{self.model.names[int(cls)]} {conf:.2f}"
            center_x = (x1 + x2) // 2
            center_y = (y1 + y2) // 2
            direction = "left" if center_x < 200 else "right" if center_x > 400 else "center"
            

            distance = depth_frame.get_distance(center_x, center_y)

            # Annotate the frame
            cv2.rectangle(color_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(color_image, f"{label} {distance:.2f}m", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

            # Publish detection info
            # detection_msg = String(data=f"{label} at ({x1},{y1},{x2},{y2}) distance: {distance:.2f}m")
            self.detection_publisher.publish(String(data=f"{center_x}, {center_y},{distance:.2f}, {direction}"))

        # Publish color and depth images
        msg_color = self.bridge.cv2_to_imgmsg(color_image, "bgr8")
        msg_color.header.stamp = self.get_clock().now().to_msg()
        msg_color.header.frame_id = "camera_color_frame"
        self.color_publisher.publish(msg_color)

        msg_depth = self.bridge.cv2_to_imgmsg(depth_image, "mono16")
        msg_depth.header.stamp = self.get_clock().now().to_msg()
        msg_depth.header.frame_id = "camera_depth_frame"
        self.depth_publisher.publish(msg_depth)

        # Display the color image
        cv2.imshow("YOLO RealSense Detection", color_image)
        cv2.waitKey(1)

    def shutdown(self):
        self.pipeline.stop()
        cv2.destroyAllWindows()


def main(args=None):
    rclpy.init(args=args)
    node = YoloRealsense()

    try:
        while rclpy.ok():
            node.process_and_publish()
            rclpy.spin_once(node, timeout_sec=0.1)
    finally:
        node.shutdown()
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()