#!/usr/bin/python3
import rclpy
from rclpy.node import Node
import pyrealsense2 as rs
import numpy as np
import cv2
from sensor_msgs.msg import Image
from std_msgs.msg import String
from cv_bridge import CvBridge

class Realsense(Node):
    def __init__(self, fps=30):
        super().__init__('realsense_node')  # Node name
        self.pipeline = rs.pipeline()
        self.config = rs.config()
        self.bridge = CvBridge()

        # Stream configuration
        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, fps)
        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, fps)

        # Image alignment
        self.align_to = rs.stream.depth
        self.align = rs.align(self.align_to)

        # Start the pipeline
        try:
            self.pipeline.start(self.config)
            self.get_logger().info("RealSense pipeline started successfully.")
        except Exception as e:
            self.get_logger().error(f"Error starting the pipeline: {e}")
            exit(1)

        # ROS Publishers
        self.color_publisher = self.create_publisher(Image, 'camera/color', 10)
        self.depth_publisher = self.create_publisher(Image, 'camera/depth', 10)
        self.detection_publisher = self.create_publisher(String, 'detection', 10)

        # Detection parameters
        self.lower_green = np.array([50, 100, 50])  # Lower bound for green
        self.upper_green = np.array([70, 255, 255])  # Upper bound for green
        self.kernel = np.ones((5, 5), np.uint8)

    def read_and_process_frames(self):
        frames = self.pipeline.wait_for_frames()
        aligned_frames = self.align.process(frames)
        depth_frame = aligned_frames.get_depth_frame()
        color_frame = aligned_frames.get_color_frame()

        if not depth_frame or not color_frame:
            self.get_logger().warn("Unable to retrieve frames.")
            return None, None, None

        # Get color and depth images
        color_image = np.asanyarray(color_frame.get_data())
        depth_image = np.asanyarray(depth_frame.get_data())

        return color_image, depth_image, depth_frame

    def detect_green_objects(self, color_image, depth_frame):
        # Convert to HSV space
        hsv_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)

        # Mask for green
        mask = cv2.inRange(hsv_image, self.lower_green, self.upper_green)

        # Clean up the mask
        mask = cv2.erode(mask, self.kernel, iterations=1)
        mask = cv2.dilate(mask, self.kernel, iterations=1)

        # Find contours
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        detected_objects = []

        for contour in contours:
            if cv2.contourArea(contour) < 140:  # Ignore small objects
                continue

            # Get the contour coordinates
            x, y, w, h = cv2.boundingRect(contour)
            center_x = x + w // 2
            center_y = y + h // 2
            distance = depth_frame.get_distance(center_x, center_y)

            detected_objects.append((x, y, w, h, distance))

        return detected_objects
        

    def process_and_publish(self):
        color_image, depth_image, depth_frame = self.read_and_process_frames()

        if color_image is None:
            return

        detected_objects = self.detect_green_objects(color_image, depth_frame)

        for x, y, w, h, distance in detected_objects:
            direction = "left" if x < 300 else "right" if x > 600 else "center"
            cv2.rectangle(color_image, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.putText(color_image, f"Distance: {distance:.2f}m", (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            self.detection_publisher.publish(String(data=f"{x}, {y},{distance:.2f}, {direction}"))

        # Publish the color image
        msg_color = self.bridge.cv2_to_imgmsg(color_image, "bgr8")
        msg_color.header.stamp = self.get_clock().now().to_msg()
        msg_color.header.frame_id = "camera_color_frame"
        self.color_publisher.publish(msg_color)

        # Publish the depth image
        msg_depth = self.bridge.cv2_to_imgmsg(depth_image, "mono16")
        msg_depth.header.stamp = self.get_clock().now().to_msg()
        msg_depth.header.frame_id = "camera_depth_frame"
        self.depth_publisher.publish(msg_depth)

        # Display the results
        cv2.imshow("Green Object Detection", color_image)
        cv2.waitKey(1)


def main(args=None):
    rclpy.init(args=args)
    rs_node = Realsense()

    try:
        while rclpy.ok():
            rs_node.process_and_publish()
            rclpy.spin_once(rs_node, timeout_sec=0.001)
    finally:
        rs_node.pipeline.stop()
        rs_node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
